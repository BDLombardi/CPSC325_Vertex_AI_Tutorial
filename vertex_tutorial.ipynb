{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPSC 325 Vertex AI Tutorial \n",
    "\n",
    "\n",
    "Vertex AI is an ML platform on the Google Cloud. As such it has easy integration with other google services such as BigQuery and Google Cloud Storage. This tutorial is going to specifically focus on using Vertex AI in notebooks.\n",
    "\n",
    "There are two main types of notebooks: Managed Notebooks and User-managed notebooks. \n",
    "* Managed notebooks instances are Google-managed environments with integrations and features that help you set up and work in an end-to-end notebook-based production environment.\n",
    "* User-managed notebooks are Deep Learning VM Images instances that are heavily customizable and are therefore ideal for users who need a lot of control over their environment. \n",
    "\n",
    "Both options are JupyterLab based and have support for both TensorFlow and PyTorch as well as GPU accelerators and the ability to sync with a Github repo. Main differences between the two are that managed notebooks are a bit easier to set up and have the ability to perform some more workflow-oriented tasks without leaving the JupyterLab interface as well as they have some options for automated notebook runs as well as automated shutdown for idle-instances. User-managed notebooks on the other hand are a lot more customizable and have better controls for networking and security needs. Also from cost perspective, it seems that User-managed notebooks are a bit cheaper. \n",
    "\n",
    "\n",
    "## Creating a Vertex AI Notebook\n",
    "\n",
    "* Make sure that you have access to the Google Cloud Console. \n",
    "* Search for Vertex AI \n",
    "* Click on Workbench and create and new notebook in User-managed Notebooks\n",
    "* Create a Notebook with your desired options\n",
    "\n",
    "## Writing Training Code\n",
    "\n",
    "For this demo we are going to write some simple training code to train a neural net on the MNIST dataset. The training code can be seen below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# importing data\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "X_train_flat = np.array([entry.flatten() for entry in X_train])\n",
    "X_test_flat = np.array([entry.flatten() for entry in X_test])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_flat = scaler.fit_transform(X_train_flat)\n",
    "X_test_flat = scaler.fit_transform(X_test_flat)\n",
    "\n",
    "X_train_flat_train, X_val,y_train_train, y_val = train_test_split(X_train_flat,y_train,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1080/1080 [==============================] - 32s 29ms/step - loss: 0.2243 - accuracy: 0.9334 - val_loss: 0.1507 - val_accuracy: 0.9568\n",
      "Epoch 2/3\n",
      "1080/1080 [==============================] - 29s 26ms/step - loss: 0.1029 - accuracy: 0.9709 - val_loss: 0.1382 - val_accuracy: 0.9622\n",
      "Epoch 3/3\n",
      "1080/1080 [==============================] - 33s 31ms/step - loss: 0.0794 - accuracy: 0.9774 - val_loss: 0.1298 - val_accuracy: 0.9665\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Reshape(target_shape=(28*28,),input_shape=(28*28,)),\n",
    "    tf.keras.layers.Dense(units = 800,activation='relu'),\n",
    "    tf.keras.layers.Dense(units = 800,activation='relu'),\n",
    "    tf.keras.layers.Dense(units = 800,activation='relu'),\n",
    "    tf.keras.layers.Dense(units = 800,activation='relu'),\n",
    "    tf.keras.layers.Dense(units=10,activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss=tf.losses.SparseCategoricalCrossentropy(from_logits=False), metrics=['accuracy'])\n",
    "history = model.fit(X_train_flat_train,y_train_train,batch_size=50,epochs=3,validation_data=(X_val,y_val))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Containerizing training code\n",
    "* `PROJECT_ID='your-cloud-project'`\n",
    "    * To get your project id run `gcloud config list --format 'value(core.project)'`\n",
    "* Convert Training notebook to .py file. \n",
    "    * `jupyter nbconvert test.ipynb --to python`\n",
    "* Make a demo directory along with a trainer directory inside of it. \n",
    "* Move your `test.py` file to the trainer directory\n",
    "\n",
    "## Creating the Dockerfile \n",
    "* In the demo directory run `touch Dockerfile` in the terminal. \n",
    "* Copy the following code into the Dockerfile. \n",
    "    ` FROM gcr.io/deeplearning-platform-release/tf2-gpu.2-8\n",
    "\n",
    "        WORKDIR /\n",
    "\n",
    "        # Copies the trainer code to the docker image.\n",
    "        COPY trainer /trainer\n",
    "\n",
    "        # Sets up the entry point to invoke the trainer.\n",
    "        ENTRYPOINT [\"python\", \"-m\", \"trainer.test\"]`\n",
    "* Create a repo in Artifact Registry\n",
    "    `REPO_NAME='class-demo'`\n",
    "\n",
    "    `gcloud artifacts repositories create $REPO_NAME --repository-format=docker \\`\n",
    "    `--location=us-west1 --description=\"Docker repository\" `\n",
    "    * Can also make it manually in the Google Cloud Console\n",
    "* Denine a variabel with the URI of the container image\n",
    "    `IMAGE_URI=us-west1-docker.pkg.dev/$PROJECT_ID/$REPO_NAME`\n",
    "* Configure docker \n",
    "    `gcloud auth configure-docker \\`\n",
    "    `us-west-docker.pkg.dev`\n",
    "* Build the container\n",
    "    ` docker build ./ -t $IMAGE_URI`\n",
    "* Push the container to Artifcat Registry. \n",
    "    `docker push $IMAGE_URI`\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Custom Training Job on Vertex AI\n",
    "* navigate to the training section of Vertex AI\n",
    "* On Training Piplines click Create. \n",
    "* In the Container settings step, select Custom Container.\n",
    "* Enter in you IMAGE_URI with your project ID. \n",
    "* Set up your machine settings and click run.  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
